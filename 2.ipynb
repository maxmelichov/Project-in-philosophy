{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk.corpus\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk \n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from string import digits\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(namefile):\n",
    "    with open(namefile+'.txt','r') as f:\n",
    "        data=f.readlines()  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45987065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(data):\n",
    "     df = pd.DataFrame(columns=['text'],data = data)\n",
    "     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df):\n",
    "    df['text_clean'] = df['text'].str.lower()\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    # remove numbers\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_5gram(df):\n",
    "    vec = CountVectorizer(ngram_range = (2, 5),stop_words='english')\n",
    "    list_= list()\n",
    "    list_=df['text_clean'].tolist()\n",
    "    X_train = vec.fit_transform(list_)\n",
    "    bigram_df=pd.DataFrame(X_train.toarray(), columns=vec.get_feature_names())\n",
    "    return bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b401afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onegram(df):\n",
    "    vec = CountVectorizer(ngram_range = (1, 1),stop_words='english')\n",
    "    list_= list()\n",
    "    list_=df['text_clean'].tolist()\n",
    "    X_train1 = vec.fit_transform(list_)\n",
    "    df_c=pd.DataFrame(X_train1.toarray(), columns=vec.get_feature_names())\n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2269a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_to_list(df):\n",
    "    listcount=list()\n",
    "    j=0\n",
    "    for val in df:\n",
    "        listcount.append([val,0])\n",
    "        for i in range(len(df[val])):\n",
    "            listcount[j][1] +=df[val][i]\n",
    "        j+=1\n",
    "        \n",
    "    listcount.sort(key=lambda y: y[1],reverse= True)\n",
    "    return listcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55da056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostcommon_to_file(listcount,file_name,flag):\n",
    "    if flag==0:\n",
    "         textfile = open(file_name+\",most common.txt\", \"w\")\n",
    "    elif flag ==1:\n",
    "        textfile = open(file_name+\",most common 2 to 5 gram.txt\", \"w\")\n",
    "    \n",
    "    for i in range(len(listcount)):\n",
    "        textfile.write(listcount[i][0])\n",
    "        textfile.write(' ')\n",
    "        textfile.write(str(listcount[i][1]))\n",
    "        textfile.write(', ')\n",
    "    print(\"The file is ready for: \"+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178723b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostcommon_to_csv(listcount,file_name,flag):\n",
    "    df=pd.DataFrame(columns=[\"common_word\",\"count\"])\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for i in range(len(listcount)):\n",
    "        list1.append(listcount[i][0])\n",
    "        list2.append(listcount[i][1])\n",
    "    df[\"common_word\"]=list1\n",
    "    df[\"count\"]=list2\n",
    "    if flag==0:\n",
    "        df.to_csv(file_name+\",most common.csv\")\n",
    "    elif flag ==1:\n",
    "        df.to_csv(file_name+\",most common 2 to 5 gram.csv\")\n",
    "    print(\"The csv is ready for: \"+file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6258acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_barplot(listcount):\n",
    "    word = []\n",
    "    frequency = []\n",
    "    plt.figure(figsize=(150,20))\n",
    "    print(len(listcount))\n",
    "    j=0\n",
    "    for i in range(len(listcount)):\n",
    "        if listcount[i][1] > 50 and j<15:\n",
    "            word.append(listcount[i][0])\n",
    "            frequency.append(listcount[i][1])\n",
    "            j+=1\n",
    "\n",
    "    sns.barplot(y= word, x=frequency, color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_wordcloud(listcount):\n",
    "    text = \"\".join(str(title) for i in range(len(listcount)) for title in listcount[i][0]+', ' )\n",
    "    wordcloud = WordCloud().generate(text)\n",
    "\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29edcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=['[Martinus Nijhoff Philosophy Texts 2] J. N. Mohanty (auth.), William McKenna, Robert M. Harlan, Laurence E. Winters (eds.) - Apriori and World_ European Contributions',\n",
    "\"066_Embree and Nenon. (2013) Husserls Ideen\",\n",
    "\"Dilthey - The Formation of the Historical World in the Human Sciences\",\n",
    "\"VI-Dilthey Selected Works, vol. 6 - Ethical and World-View Philosophy\"]\n",
    "for name in file_names:\n",
    "    data= open_file(name)\n",
    "    df = to_df(data)\n",
    "    df=clean_text(df)\n",
    "    bigram_df=bigram_5gram(df)\n",
    "    onegram_df=onegram(df)\n",
    "    listcount=most_common_to_list(onegram_df)\n",
    "    mostcommon_to_file(listcount,name,0)\n",
    "    mostcommon_to_csv(listcount,name,0)\n",
    "    listcountbi=most_common_to_list(bigram_df)\n",
    "    mostcommon_to_file(listcountbi,name,1)\n",
    "    # mostcommon_to_csv(listcountbi,name,1)\n",
    "    into_barplot(listcount)\n",
    "    into_wordcloud(listcount)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a1d278aaeab8fa8668f5602e3aa519f0aedb80b52bfb1f84d82f6ef76886618"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
